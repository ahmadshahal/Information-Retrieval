{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys, os\n",
    "libs_path = (Path(os.path.abspath(os.path.join('..'))).parent)\n",
    "sys.path.append(str(libs_path))\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "import ir_datasets\n",
    "\n",
    "from ir_measures import *\n",
    "from match_and_rank import match_and_rank, clustering_match_and_rank\n",
    "\n",
    "import ir_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_queries_corpus(dataset_name: str) -> Dict[str, str]:\n",
    "    if dataset_name == \"lifestyle\":\n",
    "        queries_corpus = dict(ir_datasets.load(\"lotte/lifestyle/dev/search\").queries_iter())\n",
    "    elif dataset_name == \"quora\":\n",
    "        queries_corpus = dict(list(ir_datasets.load(\"beir/quora/dev\").queries_iter())[:1000])\n",
    "    else:\n",
    "        queries_corpus = dict(ir_datasets.load(\"antique/test\").queries_iter())\n",
    "    return queries_corpus\n",
    "\n",
    "\n",
    "def __get_qrels_corpus(dataset_name: str):\n",
    "    if dataset_name == \"lifestyle\":\n",
    "        qrels_corpus = list(ir_datasets.load(\"lotte/lifestyle/dev/search\").qrels_iter())\n",
    "    elif dataset_name == \"quora\":\n",
    "        qrels_corpus = list(ir_datasets.load(\"beir/quora/dev\").qrels_iter())\n",
    "    else:\n",
    "        qrels_corpus = list(ir_datasets.load(\"antique/test\").qrels_iter())\n",
    "    return qrels_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ground_truth(dataset_name: str):\n",
    "    queries_corpus = __get_queries_corpus(dataset_name)\n",
    "    qrels_corpus = __get_qrels_corpus(dataset_name)\n",
    "    ground_truth = {}\n",
    "    for query_id, query in queries_corpus.items():\n",
    "        relevant_docs = [(item.doc_id, item.relevance) for item in qrels_corpus if item.query_id == query_id]\n",
    "        ground_truth[query_id] = dict(relevant_docs)\n",
    "    return ground_truth\n",
    "\n",
    "\n",
    "def _get_search_results(dataset_name: str):\n",
    "    search_results = {}\n",
    "    queries_corpus = __get_queries_corpus(dataset_name)\n",
    "    for query_id, query in queries_corpus.items():\n",
    "        # print(f'Evaluating query {query_id}')\n",
    "        results = match_and_rank(query, dataset_name)\n",
    "        relevance_documents = [(doc_id, score) for doc_id, score in results.items()]\n",
    "        search_results[query_id] = dict(relevance_documents)\n",
    "    return search_results\n",
    "\n",
    "def _get_clustering_search_results(dataset_name: str):\n",
    "    search_results = {}\n",
    "    queries_corpus = __get_queries_corpus(dataset_name)\n",
    "    for query_id, query in queries_corpus.items():\n",
    "        results = clustering_match_and_rank(query, dataset_name)\n",
    "        relevance_documents = [(doc_id, score) for doc_id, score in results.items()]\n",
    "        search_results[query_id] = dict(relevance_documents)\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{R@5: 0.08066153575893291, R@10: 0.13392374015710196, AP: 0.2275471168023467, RR: 0.7656958906370507, AP@10: 0.10606845337818997, P@10: 0.39799999999999985}\n",
      "{R@5: 0.225449969694574, R@10: 0.28140366827417185, AP: 0.18797523744808736, RR: 0.30351466896690943, AP@10: 0.16861801215461153, P@10: 0.07865707434052781}\n",
      "{R@5: 0.7301994872774282, R@10: 0.8020360205807264, AP: 0.6502576094372834, RR: 0.7066835811631382, AP@10: 0.6353993866812463, P@10: 0.13289999999999866}\n"
     ]
    }
   ],
   "source": [
    "def evaluate(dataset_name: str):\n",
    "    ground_truth = _get_ground_truth(dataset_name)\n",
    "    search_results = _get_search_results(dataset_name)\n",
    "    # search_results = _get_clustering_search_results(dataset_name)\n",
    "\n",
    "    evaluation_results = ir_measures.calc_aggregate([AP@10, AP, RR, P@10, R@5, R@10], ground_truth, search_results)\n",
    "    print(evaluation_results)\n",
    "\n",
    "\n",
    "evaluate(\"antique\")\n",
    "# {R@10: 0.13392374015710196, AP@10: 0.10606845337818997, AP: 0.2275471168023467, R@5: 0.08066153575893291, P@10: 0.39799999999999985, RR: 0.7656958906370507}\n",
    "\n",
    "evaluate(\"lifestyle\")\n",
    "# {P@10: 0.07865707434052781, R@10: 0.28140366827417185, AP@10: 0.16861801215461153, R@5: 0.225449969694574, AP: 0.18797523744808736, RR: 0.30351466896690943}\n",
    "\n",
    "evaluate(\"quora\")\n",
    "# {AP@10: 0.6308512246902128, R@5: 0.7224104784104783, P@10: 0.14700000000000057, R@10: 0.7930852406852404, RR: 0.7238663335960567, AP: 0.6498598451096447}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
