{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys, os\n",
    "libs_path = (Path(os.path.abspath(os.path.join('..'))).parent)\n",
    "sys.path.append(str(libs_path))\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "import ir_datasets\n",
    "\n",
    "from ir_measures import *\n",
    "from match_and_rank import match_and_rank, clustering_match_and_rank\n",
    "\n",
    "import ir_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_queries_corpus(dataset_name: str) -> Dict[str, str]:\n",
    "    if dataset_name == \"lifestyle\":\n",
    "        queries_corpus = dict(ir_datasets.load(\"lotte/lifestyle/dev/search\").queries_iter())\n",
    "    elif dataset_name == \"quora\":\n",
    "        queries_corpus = dict(list(ir_datasets.load(\"beir/quora/dev\").queries_iter())[:1000])\n",
    "    else:\n",
    "        queries_corpus = dict(ir_datasets.load(\"antique/test\").queries_iter())\n",
    "    return queries_corpus\n",
    "\n",
    "\n",
    "def __get_qrels_corpus(dataset_name: str):\n",
    "    if dataset_name == \"lifestyle\":\n",
    "        qrels_corpus = list(ir_datasets.load(\"lotte/lifestyle/dev/search\").qrels_iter())\n",
    "    elif dataset_name == \"quora\":\n",
    "        qrels_corpus = list(ir_datasets.load(\"beir/quora/dev\").qrels_iter())\n",
    "    else:\n",
    "        qrels_corpus = list(ir_datasets.load(\"antique/test\").qrels_iter())\n",
    "    return qrels_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ground_truth(dataset_name: str):\n",
    "    queries_corpus = __get_queries_corpus(dataset_name)\n",
    "    qrels_corpus = __get_qrels_corpus(dataset_name)\n",
    "    ground_truth = {}\n",
    "    for query_id, query in queries_corpus.items():\n",
    "        relevant_docs = [(item.doc_id, item.relevance) for item in qrels_corpus if item.query_id == query_id]\n",
    "        ground_truth[query_id] = dict(relevant_docs)\n",
    "    return ground_truth\n",
    "\n",
    "\n",
    "def _get_search_results(dataset_name: str):\n",
    "    search_results = {}\n",
    "    queries_corpus = __get_queries_corpus(dataset_name)\n",
    "    for query_id, query in queries_corpus.items():\n",
    "        # print(f'Evaluating query {query_id}')\n",
    "        results = match_and_rank(query, dataset_name)\n",
    "        relevance_documents = [(doc_id, score) for doc_id, score in results.items()]\n",
    "        search_results[query_id] = dict(relevance_documents)\n",
    "    return search_results\n",
    "\n",
    "def _get_clustering_search_results(dataset_name: str):\n",
    "    search_results = {}\n",
    "    queries_corpus = __get_queries_corpus(dataset_name)\n",
    "    for query_id, query in queries_corpus.items():\n",
    "        results = clustering_match_and_rank(query, dataset_name)\n",
    "        relevance_documents = [(doc_id, score) for doc_id, score in results.items()]\n",
    "        search_results[query_id] = dict(relevance_documents)\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n",
      "Loading antique dataset 403666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m     evaluation_results \u001b[38;5;241m=\u001b[39m ir_measures\u001b[38;5;241m.\u001b[39mcalc_aggregate([AP\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m10\u001b[39m, AP, RR, P\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m10\u001b[39m, R\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m5\u001b[39m, R\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m10\u001b[39m], ground_truth, search_results)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(evaluation_results)\n\u001b[0;32m---> 10\u001b[0m evaluate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mantique\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# {R@10: 0.13392374015710196, AP@10: 0.10606845337818997, AP: 0.2275471168023467, R@5: 0.08066153575893291, P@10: 0.39799999999999985, RR: 0.7656958906370507}\u001b[39;00m\n\u001b[1;32m     13\u001b[0m evaluate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlifestyle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(dataset_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m      2\u001b[0m     ground_truth \u001b[38;5;241m=\u001b[39m _get_ground_truth(dataset_name)\n\u001b[0;32m----> 3\u001b[0m     search_results \u001b[38;5;241m=\u001b[39m _get_search_results(dataset_name)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# search_results = _get_clustering_search_results(dataset_name)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     evaluation_results \u001b[38;5;241m=\u001b[39m ir_measures\u001b[38;5;241m.\u001b[39mcalc_aggregate([AP\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m10\u001b[39m, AP, RR, P\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m10\u001b[39m, R\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m5\u001b[39m, R\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m10\u001b[39m], ground_truth, search_results)\n",
      "Cell \u001b[0;32mIn[24], line 16\u001b[0m, in \u001b[0;36m_get_search_results\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m     13\u001b[0m queries_corpus \u001b[38;5;241m=\u001b[39m __get_queries_corpus(dataset_name)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query_id, query \u001b[38;5;129;01min\u001b[39;00m queries_corpus\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# print(f'Evaluating query {query_id}')\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     results \u001b[38;5;241m=\u001b[39m match_and_rank(query, dataset_name)\n\u001b[1;32m     17\u001b[0m     relevance_documents \u001b[38;5;241m=\u001b[39m [(doc_id, score) \u001b[38;5;28;01mfor\u001b[39;00m doc_id, score \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m     18\u001b[0m     search_results[query_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(relevance_documents)\n",
      "File \u001b[0;32m~/ITE/IR/ir-search-engine-master/apps/match-and-rank/match_and_rank.py:21\u001b[0m, in \u001b[0;36mmatch_and_rank\u001b[0;34m(query, dataset_name, similarity_threshold)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatch_and_rank\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m, dataset_name: \u001b[38;5;28mstr\u001b[39m, similarity_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m):\n\u001b[1;32m     19\u001b[0m     processed_query \u001b[38;5;241m=\u001b[39m _process_query(query, dataset_name)\n\u001b[0;32m---> 21\u001b[0m     loaded_vectorizer \u001b[38;5;241m=\u001b[39m get_vectorizer(dataset_name)\n\u001b[1;32m     22\u001b[0m     loaded_tfidf_matrix \u001b[38;5;241m=\u001b[39m get_tfidf_matrix(dataset_name)\n\u001b[1;32m     24\u001b[0m     query_vector \u001b[38;5;241m=\u001b[39m loaded_vectorizer\u001b[38;5;241m.\u001b[39mtransform([processed_query])\n",
      "File \u001b[0;32m~/ITE/IR/ir-search-engine-master/libs/storage.py:13\u001b[0m, in \u001b[0;36mget_vectorizer\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vectorizer\u001b[39m(dataset_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/ahmadsmac/ITE/IR/ir-search-engine-master/models/vectorizer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:314\u001b[0m, in \u001b[0;36mBaseEstimator.__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m state\n\u001b[0;32m--> 314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    316\u001b[0m         pickle_version \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sklearn_version\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre-0.18\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate(dataset_name: str):\n",
    "    ground_truth = _get_ground_truth(dataset_name)\n",
    "    search_results = _get_search_results(dataset_name)\n",
    "    # search_results = _get_clustering_search_results(dataset_name)\n",
    "\n",
    "    evaluation_results = ir_measures.calc_aggregate([AP@10, AP, RR, P@10, R@5, R@10], ground_truth, search_results)\n",
    "    print(evaluation_results)\n",
    "\n",
    "\n",
    "evaluate(\"antique\")\n",
    "# {R@10: 0.13392374015710196, AP@10: 0.10606845337818997, AP: 0.2275471168023467, R@5: 0.08066153575893291, P@10: 0.39799999999999985, RR: 0.7656958906370507}\n",
    "\n",
    "evaluate(\"lifestyle\")\n",
    "# {P@10: 0.07865707434052781, R@10: 0.28140366827417185, AP@10: 0.16861801215461153, R@5: 0.225449969694574, AP: 0.18797523744808736, RR: 0.30351466896690943}\n",
    "\n",
    "evaluate(\"quora\")\n",
    "# {AP@10: 0.6308512246902128, R@5: 0.7224104784104783, P@10: 0.14700000000000057, R@10: 0.7930852406852404, RR: 0.7238663335960567, AP: 0.6498598451096447}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
